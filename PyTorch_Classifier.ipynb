{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import glob as glob\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from IPython import display\n",
    "import h5py\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_Dataset(Dataset):\n",
    "    def __init__(self, file, transform=None, target_transform=None):\n",
    "        with open(file, 'r') as f:\n",
    "            data = f.readlines()\n",
    "        self.df = []\n",
    "        self.soln = []\n",
    "        self.soln_list = []\n",
    "        self.one_hot_solns = {}\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            self.df.append([float(x) for x in data[i].split(',')[:-1]])\n",
    "            self.soln.append(data[i].split(',')[-1][:-1])\n",
    "            \n",
    "        for s in self.soln:\n",
    "            if s not in self.soln_list:\n",
    "                self.soln_list.append(s)\n",
    "                \n",
    "        for s in self.soln_list:\n",
    "            z = np.zeros(len(self.soln_list))\n",
    "            idx = self.soln_list.index(s)\n",
    "            z[idx] = 1\n",
    "            self.one_hot_solns[s] = z\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = np.array(self.df[idx])\n",
    "        one_hot_label = self.one_hot_solns[self.soln[idx]]\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return data, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AE_Dataset('data_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.14217606, 0.        , 0.00093796, 0.00217202, 0.0003608 ,\n",
       "        0.00047538, 0.05378675, 0.06140351, 0.14838068, 0.        ,\n",
       "        0.        , 0.        , 0.        ]),\n",
       " array([1., 0., 0.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.randint(0, dataset.__len__())\n",
    "\n",
    "dataset.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Subset(dataset, range(0,int(len(dataset)*0.7)))\n",
    "testset = Subset(dataset, range(int(len(dataset)*0.7), len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160603"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LeakyReLU to enable negative values\n",
    "class Classifier_Leaky(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.linear_lrelu_stack = nn.Sequential(\n",
    "            nn.Linear(kwargs[\"input_shape\"], 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, kwargs[\"output_shape\"]),\n",
    "            #nn.Softmax(dim=1))\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_lrelu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier_Leaky(input_shape=13, output_shape=3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss() # nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 879/879 [00:04<00:00, 193.04batch/s, accuracy=97, loss=0.0228]\n",
      "Epoch 2: 100%|██████████| 879/879 [00:04<00:00, 191.48batch/s, accuracy=98, loss=0.038] \n",
      "Epoch 3: 100%|██████████| 879/879 [00:04<00:00, 189.98batch/s, accuracy=99, loss=0.0015] \n",
      "Epoch 4: 100%|██████████| 879/879 [00:04<00:00, 193.42batch/s, accuracy=99, loss=0.0184] \n",
      "Epoch 5: 100%|██████████| 879/879 [00:04<00:00, 191.03batch/s, accuracy=98, loss=0.0141]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "path = './Classifier_MkII.pth'\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(train_loader, unit='batch') as tepoch:\n",
    "        start = time.time()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data, target in tepoch:\n",
    "            score = 0\n",
    "            total+=1\n",
    "            tepoch.set_description(f'Epoch {epoch+1}')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(data.float())\n",
    "            train_loss = criterion(outputs, target.float())\n",
    "            train_loss.backward()\n",
    "\n",
    "            #nn.utils.clip_grad_norm(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            predicted = []\n",
    "            actual = []\n",
    "            for i in range(len(outputs[0])):\n",
    "                if outputs[0][i] >= 0.5:\n",
    "                    predicted.append(dataset.soln_list[i])\n",
    "                if target[0][i] >= 0.5:\n",
    "                    actual.append(dataset.soln_list[i])\n",
    "            for i in range(len(actual)):\n",
    "                for j in range(4):\n",
    "                    try:\n",
    "                        if predicted[j] == actual[i]:\n",
    "                            score+=1\n",
    "                    except IndexError:\n",
    "                        score+=0\n",
    "            score/=len(actual)\n",
    "            correct+=score\n",
    "            \n",
    "            tepoch.set_postfix(loss=round(train_loss.item(),4), accuracy=100*correct//total)\n",
    "            \n",
    "        torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  Background\n",
      "Acutal:  Background\n"
     ]
    }
   ],
   "source": [
    "# eval one at a time\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=True)\n",
    "dataiter = iter(test_loader)\n",
    "data, labels = dataiter.next()\n",
    "\n",
    "model = Classifier_Leaky(input_shape=13, output_shape=3)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    outputs = model(data.float())\n",
    "    \n",
    "    for i in range(len(outputs[0])):\n",
    "        if outputs[0][i] >= 0.5:\n",
    "            predicted.append(dataset.soln_list[i])\n",
    "        if labels[0][i] >= 0.5:\n",
    "            actual.append(dataset.soln_list[i])\n",
    "\n",
    "    print('Predicted: ', *predicted)\n",
    "    print('Acutal: ',*actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby Powder\n",
      "Baby Powder Accuracy: 81 %\n",
      "Riboflavin\n",
      "Riboflavin Accuracy: 99 %\n"
     ]
    }
   ],
   "source": [
    "# eval each soln\n",
    "model = Classifier_Leaky(input_shape=13, output_shape=3)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "for soln in dataset.soln_list:\n",
    "    if soln == 'Background':\n",
    "        pass\n",
    "    else:\n",
    "        idxs = []\n",
    "        for d in range(len(dataset.soln)):\n",
    "            if dataset.soln[d] == soln:\n",
    "                idxs.append(d)\n",
    "        \n",
    "        preds = {}\n",
    "        tc = 0\n",
    "        t = 0\n",
    "        with torch.no_grad():\n",
    "            print(soln)\n",
    "            for j in idxs:\n",
    "                data, labels = dataset.__getitem__(j)\n",
    "\n",
    "                outputs = model(torch.from_numpy(np.array([data])).float())\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                _, actual = torch.max(torch.from_numpy(np.array([labels])), 1)\n",
    "\n",
    "                correct = (predicted==actual).sum().item()\n",
    "                tc+=correct\n",
    "                t+=len(actual)\n",
    "                \n",
    "            print(f'{soln} Accuracy: {tc*100//t} %')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 160603/160603 [03:03<00:00, 872.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Background': {'Background': 147190}, 'Baby Powder': {'Baby Powder': 4098, 'Riboflavin': 958, 'Background': 1}, 'Riboflavin': {'Riboflavin': 8293, 'Baby Powder': 63}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create confusion matrix\n",
    "model = Classifier_Leaky(input_shape=13, output_shape=3)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "soln_cm = {}\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=dataset.__len__()) as pbar:\n",
    "        for idx in range(dataset.__len__()):\n",
    "            pbar.set_description(f'Progress')\n",
    "            pbar.update(1)\n",
    "            \n",
    "            data, labels = dataset.__getitem__(idx)\n",
    "            outputs = model(torch.from_numpy(np.array([data])).float())\n",
    "            \n",
    "            lo = list(outputs[0])\n",
    "            ll = list(labels)\n",
    "\n",
    "            pred_soln = dataset.soln_list[lo.index(max(lo))]\n",
    "            act_soln = dataset.soln_list[ll.index(max(ll))]\n",
    "            \n",
    "            if act_soln not in soln_cm:\n",
    "                soln_cm[act_soln] = {}\n",
    "            if pred_soln not in soln_cm[act_soln]:\n",
    "                soln_cm[act_soln][pred_soln] = 0\n",
    "            soln_cm[act_soln][pred_soln] += 1\n",
    "            \n",
    "print(soln_cm)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
